{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from geopy.geocoders import Nominatim, GoogleV3, Bing\n",
    "import folium\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import googleCreds\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "import json\n",
    "import csv\n",
    "from urllib.request import urlopen\n",
    "\n",
    "def getCompaniesDataframe(googleAPIKey,\n",
    "                          jobName = \"data scientist\",\n",
    "                          locationName = \"Milano Lombardia\",\n",
    "                          resource = \"https://it.indeed.com/\",\n",
    "                          maxPages = 1,\n",
    "                          dfPath = \"data/dfCompanies.pkl\",\n",
    "                          savePickle = True,\n",
    "                          dropNAs = True):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    The function returns a dataframe with following features:\n",
    "\n",
    "    - company name (companyName): str\n",
    "    - job name (jobName): str\n",
    "    - link to the description of the position (link): str\n",
    "    - latitude of company's headquarters based on Google Maps Search (lt): float\n",
    "    - longitude of company's headquarters based on Google Maps Search (lg): float\n",
    "    - address of company's headquarters based on Google Maps Search (address): str\n",
    "\n",
    "    If getting one of the features was unsuccesful it is replaced by np.nan (numpy NAN).\n",
    "\n",
    "    Inputs:\n",
    "        googleAPIKey(str):  path to Google Maps API key\n",
    "\n",
    "        jobName     (str):  job name for the search,\n",
    "                            default: \"data scientist\"\n",
    "\n",
    "        locaionName (str):  location name,\n",
    "                            default: \"Milano%2C+Lombardia\"\n",
    "\n",
    "        resource    (str):  URL of job source, by now available only default value,\n",
    "                            default: \"https://it.indeed.com/\"\n",
    "\n",
    "        maxPages    (int):  number of pages of results to scan,\n",
    "                            default: 1\n",
    "\n",
    "        dfPath      (str):  path to save a dataframe as CSV file,\n",
    "                            default: \"dfCompanies.csv\"\n",
    "\n",
    "        saveCSV     (bool): True, if csv file should be saved to dfPath,\n",
    "                            default: True\n",
    "\n",
    "        dropNAs     (bool): True, if rows containing np.nan values should be dropped from a dataframe,\n",
    "                            default: True\n",
    "    Outputs:\n",
    "\n",
    "        pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    jobName = \"+\".join(jobName.split())\n",
    "    city = locationName.split()[0]\n",
    "    locationName = \"%2C+\".join(locationName.split())\n",
    "\n",
    "    #To be extended if other resources are used\n",
    "    if resource == \"https://it.indeed.com/\":\n",
    "        if maxPages>1:\n",
    "            urlList = [f\"https://it.indeed.com/offerte-lavoro?q={jobName}&l={locationName}\"]\n",
    "            urlList+=[f\"https://it.indeed.com/jobs?q={jobName}&l={locationName}&start={i}0\" for i in range(1,maxPages+1)]\n",
    "        else:\n",
    "            urlList = [f\"https://it.indeed.com/offerte-lavoro?q={jobName}&l={locationName}\"]\n",
    "\n",
    "\n",
    "    companyInfo = {\"companyName\":[],\n",
    "                   \"jobName\":[],\n",
    "                   \"link\":[],\n",
    "                   \"lt\" : [],\n",
    "                   \"lg\" : [],\n",
    "                   \"address\" : []}\n",
    "\n",
    "    for url in urlList:\n",
    "        session = requests.session()\n",
    "        response = session.get(url)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        for element in soup.find_all('span', class_='company'):\n",
    "            #print(element)\n",
    "            #input()\n",
    "            try:\n",
    "                name = element.find('a', class_=\"turnstileLink\").text.strip()\n",
    "                #print(name)\n",
    "            except:\n",
    "                name = element.text.strip()\n",
    "                #print(name)\n",
    "            companyInfo[\"companyName\"].append(name)\n",
    "\n",
    "        for element in soup.find_all('h2', class_='title'):\n",
    "            #print(element)\n",
    "            #print(element.find('a').get(\"href\"))\n",
    "            try:\n",
    "                currentLink = element.find('a').get(\"href\")\n",
    "                companyInfo[\"link\"].append(\"https://it.indeed.com\"+currentLink)\n",
    "                #print(\"Link: \"+\"https://it.indeed.com\"+currentLink)\n",
    "            except:\n",
    "                print(\"Error adding link\")\n",
    "                companyInfo[\"link\"].append(np.nan)\n",
    "                #print(element)\n",
    "                #input()\n",
    "            try:\n",
    "                jobName = element.find('a', class_=\"jobtitle turnstileLink \").text.strip()\n",
    "                #print(jobName)\n",
    "                #print(\"JobName Try Branch\")\n",
    "            except:\n",
    "                jobName = element.text.strip()\n",
    "                #print(jobName)\n",
    "                #print(\"JobName Except Branch\")\n",
    "            #print(jobName)\n",
    "            companyInfo[\"jobName\"].append(jobName)\n",
    "\n",
    "    #Sanity check if any info was lost/missed\n",
    "    assert len(companyInfo[\"companyName\"]) == len(companyInfo[\"jobName\"]) == len(companyInfo[\"link\"])\n",
    "\n",
    "    # In order to get companies' locations I need their address which I can get using Google Maps API.\n",
    "    # I had to create an account for that purpose.\n",
    "    # Credentials are stored in googleCreds.py for security reasons.\n",
    "    geolocator = GoogleV3(api_key = googleAPIKey)\n",
    "\n",
    "    for company in companyInfo[\"companyName\"]:\n",
    "        rawName = str(company+\" Milano\").replace(\" \",\"+\")\n",
    "        url = 'https://maps.googleapis.com/maps/api/geocode/json?'+'address={}&key={}'.format(rawName,googleCreds.GOOGLE_API_KEY)\n",
    "        p = {'address' : 'Milano'}\n",
    "        r = requests.get(url, params = p).json()\n",
    "\n",
    "        time.sleep(0.5)\n",
    "        try:\n",
    "            results = r['results']\n",
    "            results = results[0]\n",
    "\n",
    "            location = geolocator.geocode(results[\"formatted_address\"])\n",
    "            if \"Milan\" in location.address:\n",
    "                print(company + \" was succesfully added with address:\\n\" + location.address + \"\\n\")\n",
    "\n",
    "                companyInfo[\"lt\"].append(location.latitude)\n",
    "                companyInfo[\"lg\"].append(location.longitude)\n",
    "                companyInfo[\"address\"].append(location.address)\n",
    "            else:\n",
    "                print(company + \" was skipped. \"+location.address+\" is not in Milano\\n\")\n",
    "                companyInfo[\"lt\"].append(np.nan)\n",
    "                companyInfo[\"lg\"].append(np.nan)\n",
    "                companyInfo[\"address\"].append(np.nan)\n",
    "        except:\n",
    "            print(company + \" was skipped. Probably was not found\\n\")\n",
    "            companyInfo[\"lt\"].append(np.nan)\n",
    "            companyInfo[\"lg\"].append(np.nan)\n",
    "            companyInfo[\"address\"].append(np.nan)\n",
    "\n",
    "    #Sanity check if any info was lost/missed\n",
    "    assert len(companyInfo[\"companyName\"]) == len(companyInfo[\"jobName\"]) == len(companyInfo[\"link\"])\n",
    "    assert len(companyInfo[\"lt\"]) == len(companyInfo[\"lg\"]) == len(companyInfo[\"address\"]) == len(companyInfo[\"link\"])\n",
    "    print(\"Assertion succesful. Creating Dataframe\")\n",
    "\n",
    "    dfCompanies = pd.DataFrame(companyInfo)\n",
    "    dfCompanies = dfCompanies[dfCompanies[\"address\"].astype(str).str.contains(city)]\n",
    "\n",
    "    if dropNAs:\n",
    "        dfCompanies.dropna(inplace = True)\n",
    "\n",
    "    if savePickle:\n",
    "        dfCompanies.to_pickle(dfPath)\n",
    "\n",
    "    return dfCompanies\n",
    "\n",
    "\n",
    "# Green Zones\n",
    "# The next step is to analyze how green each zone of Milan is. I used data on green zones in order to obtain Vegetation Concentration (area of green zones relative to total area).\n",
    "def getGreenZonesDataframe(resource = \"https://dati.comune.milano.it/dataset/da6bc86d-c27f-4256-84eb-86c35dad7d0e/resource/bd55cd57-4dd7-4d72-b182-de4f4b7de8c6/download/ds339_territorioambiente_aree-verdi-zona-superficie_2014.csv\",\n",
    "                          dfPath = \"data/\",\n",
    "                          savePickle = True):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    The function returns a dataframe with following features:\n",
    "    - City zone number (ZONADEC): int\n",
    "    - Total area of green zones (GreenArea): float\n",
    "    - Total area of the city zone (TotalArea): float\n",
    "    - Concentration of green calculated as GreenArea/TotalArea (GreenConc): float\n",
    "\n",
    "    Source: https://dati.comune.milano.it/dataset/ds339-territorioambiente-aree-verdi-zona-superficie-2014\n",
    "    Last Access Date: 11/08/2020\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "        resource    (str):  URL of source, by now only default value should be used,\n",
    "                            default: \"https://dati.comune.milano.it/dataset/da6bc86d-c27f-4256-84eb-86c35dad7d0e/resource/bd55cd57-4dd7-4d72-b182-de4f4b7de8c6/download/ds339_territorioambiente_aree-verdi-zona-superficie_2014.csv\"\n",
    "\n",
    "        dfPath      (str):  path to save dataframes as pickle files,\n",
    "                            default: \"data/\"\n",
    "\n",
    "        savePickle  (bool): True, if pickle files should be saved to dfPath,\n",
    "                            default: True\n",
    "\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "        pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    dfGreenRaw = pd.read_csv(resource,\n",
    "                         header = 0, sep = \";\", encoding='latin-1')\n",
    "\n",
    "\n",
    "    dfGreenRaw[\"Superficie totale in mq\"] = dfGreenRaw[\"Superficie totale in mq\"].apply(lambda x: float(str(x).replace(\",\",\".\")))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dfGreenRaw = dfGreenRaw.groupby(by=\"Zona\").sum()\n",
    "    dfGreenRaw = dfGreenRaw.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Getting info on total area of each zone from Wikipedia\n",
    "\n",
    "    # In[18]:\n",
    "\n",
    "\n",
    "    dfZones = pd.read_html('https://en.wikipedia.org/wiki/Municipalities_of_Milan',\n",
    "                              flavor='bs4')\n",
    "    dfZones = dfZones[1][:9]\n",
    "\n",
    "\n",
    "\n",
    "    # Merging two Data frames and calculating the new column\n",
    "\n",
    "    dfGreen = pd.concat([dfGreenRaw, dfZones],axis = 1)[[\"Zona\",\"Superficie totale in mq\",\"Area(km2)\"]]\n",
    "    #Had to rename column because geojson file had ZONADEC variable for zone number.\n",
    "    #I'll need that when creating a map.\n",
    "    dfGreen.columns = [\"ZONADEC\",\"GreenArea\", \"TotalArea\"]\n",
    "\n",
    "    #Converting m2 to km2\n",
    "    dfGreen[\"GreenArea\"] = dfGreen[\"GreenArea\"]/1000000\n",
    "\n",
    "    dfGreen[\"GreenConc\"] = dfGreen[\"GreenArea\"]/dfGreen[\"TotalArea\"]\n",
    "\n",
    "    if savePickle:\n",
    "        dfGreenRaw.to_pickle(dfPath+'dfGreenRaw.pkl')\n",
    "        dfZones.to_pickle(dfPath+'dfZones.pkl')\n",
    "        dfGreen.to_pickle(dfPath+\"dfGreen.pkl\")\n",
    "\n",
    "    return dfGreen\n",
    "\n",
    "# ### 5. Air Quality\n",
    "# In this section I analyze data on contamination for 2019 and 2020 obtained from stations located in Milano.\n",
    "# I will calculate an Eco score which is an inverted value of mean normalized concentrations of contaminants.\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "def getAirQualityDataframe(resource = ['https://dati.comune.milano.it/dataset/3e752fec-06fd-421b-ae9b-4d5d7a177640/resource/698a58e6-f276-44e1-92b1-3d2b81a4ad47/download/qaria_datoariagiornostazione_2020-01-08.csv',\n",
    "                                      'https://dati.comune.milano.it/dataset/ccf8b61d-728f-46e7-bee9-e685c7b6cd35/resource/88c1e729-420e-433f-9397-875b54aa471d/download/qaria_datoariagiornostazione_2021-01-01.csv'],\n",
    "                          dfPath = \"data/\",\n",
    "                          savePickle = True,\n",
    "                          plot = False):\n",
    "\n",
    "    \"\"\"\n",
    "    The function returns a dataframe with following features:\n",
    "    - Station number (id_amat): int\n",
    "    - Absolute median value of contaminant concentrations (valore): float\n",
    "    - Median value of scaled contaminant concentrations (normv): float\n",
    "    - Station name (name): str\n",
    "    - Coordinates of a station as a list [latitude, longitude] (coords): list of floats\n",
    "    - Latitude of a station (lt): float\n",
    "    - Longitude of a station (lg): float\n",
    "\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "        resource    (list of str):  URL of source, by now only default value should be used,\n",
    "                            default: \"https://dati.comune.milano.it/dataset/da6bc86d-c27f-4256-84eb-86c35dad7d0e/resource/bd55cd57-4dd7-4d72-b182-de4f4b7de8c6/download/ds339_territorioambiente_aree-verdi-zona-superficie_2014.csv\"\n",
    "\n",
    "        dfPath      (str):  path to save dataframes as pickle files,\n",
    "                            default: \"data/\"\n",
    "\n",
    "        savePickle  (bool): True, if pickle files should be saved to dfPath,\n",
    "                            default: True\n",
    "\n",
    "        plot  (bool):       if True, html bar plots for each station will be saved to dfPath,\n",
    "                            default: False\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "        pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    for i,r in enumerate(resource):\n",
    "        if i==0:\n",
    "            dfAirRaw = pd.read_csv(r, sep=None)\n",
    "        else:\n",
    "            dfT = pd.read_csv(r, sep=None)\n",
    "            dfAirRaw = pd.concat([dfAirRaw,dfT])\n",
    "\n",
    "    dfAirRaw.dropna(inplace = True)\n",
    "\n",
    "    dfAir = dfAirRaw\n",
    "    dfAir['data']=pd.to_datetime(dfAir['data'], format='%Y-%m-%d')\n",
    "    dfAir[\"normv\"] = dfAir['valore'] / dfAir.groupby('inquinante')['valore'].transform('max')\n",
    "\n",
    "    dfAir = dfAir.groupby(by=\"stazione_id\").median()\n",
    "\n",
    "    dfAir = dfAir.reset_index()\n",
    "    dfAir.columns = [\"id_amat\", \"valore\", \"normv\"]\n",
    "\n",
    "\n",
    "    # Retrieving data from geojson for stations.\n",
    "    #Source: https://dati.comune.milano.it/dataset/ds484_stazioni_di_monitoraggio_inquinanti_atmosferici_dellarpa_sit/resource/635c6508-b335-48b1-b3c8-d43e78ad3380\n",
    "\n",
    "    stationsPath = 'https://dati.comune.milano.it/dataset/d6960c75-0a02-4fda-a85f-3b1c4aa725d6/resource/635c6508-b335-48b1-b3c8-d43e78ad3380/download/qaria_stazione.geojson'\n",
    "\n",
    "    # with open(stationsPath) as data_file:\n",
    "    #     data = json.load(data_file)\n",
    "    stationsData = urlopen(stationsPath)\n",
    "    stationsData = json.load(stationsData)\n",
    "    dctStations = {\"id_amat\":[],\n",
    "                   \"name\" : [],\n",
    "                   \"coords\" : []}\n",
    "\n",
    "    for i in stationsData[\"features\"]:\n",
    "        dctStations[\"id_amat\"].append(i[\"properties\"][\"id_amat\"])\n",
    "        dctStations[\"name\"].append(i[\"properties\"][\"nome\"])\n",
    "        dctStations[\"coords\"].append([i[\"geometry\"][\"coordinates\"][1], i[\"geometry\"][\"coordinates\"][0]])\n",
    "\n",
    "    dfStations = pd.DataFrame(dctStations)\n",
    "    dfAirStations = dfAir.merge(dfStations, left_on='id_amat', right_on='id_amat')\n",
    "\n",
    "\n",
    "\n",
    "    # Need to separate the coordinates for further modelling\n",
    "    dfAirStations[\"lt\"] = dfAirStations[\"coords\"].map(lambda x: x[0])\n",
    "    dfAirStations[\"lg\"] = dfAirStations[\"coords\"].map(lambda x: x[1])\n",
    "\n",
    "\n",
    "\n",
    "    if savePickle:\n",
    "        dfAirRaw.to_pickle(dfPath+'dfAirRaw.pkl')\n",
    "        dfAir.to_pickle(dfPath+'dfAir.pkl')\n",
    "        dfStations.to_pickle(dfPath+\"dfStations.pkl\")\n",
    "        dfAirStations.to_pickle(dfPath+\"dfAirStations.pkl\")\n",
    "\n",
    "    if plot:\n",
    "        for station in dfAirRaw[\"stazione_id\"].unique():\n",
    "            f = px.bar(dfAirRaw, x='data', y='normv', color='inquinante', title=f\"Station #{station}\")\n",
    "            f.write_html(dfPath+f\"Air_Station_{station}.html\")\n",
    "    return dfAirStations\n",
    "\n",
    "\n",
    "def getLoc(address, annot = False, api_key = googleCreds.GOOGLE_API_KEY):\n",
    "    \"\"\"\n",
    "    The function returns coordinates of a given address.\n",
    "\n",
    "    Input:\n",
    "    address (str): address\n",
    "    annot (bool): if True, messages on result are displayed\n",
    "    api_key (str): API key for GoogleV3 geocoder,\n",
    "                   can be obtained at https://console.cloud.google.com/ (look for Geocoding API)\n",
    "\n",
    "    Output:\n",
    "    list(float): [latitude, longitude] or np.nan if not found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        geolocator = GoogleV3(api_key = api_key)\n",
    "        location = geolocator.geocode(address)\n",
    "        if annot:\n",
    "            print(address + \" was succesfully added\\n\")\n",
    "        return [location[1][0], location[1][1]]\n",
    "\n",
    "    except:\n",
    "        if annot:\n",
    "            print(address + \" was skipped. Probably was not found\\n\")\n",
    "        return np.nan\n",
    "\n",
    "def getAccommodationDF(minPrice = 500, maxPrice = 5000, maxPages = 10, dfPath = \"data/\", savePickle = True):\n",
    "\n",
    "    \"\"\"\n",
    "    The function returns a dataframe with following features:\n",
    "    - Accommodation id (id): str\n",
    "    - Accommodation type (type): str\n",
    "    - Accommodation address (address): str\n",
    "    - Accommodation price (price): float\n",
    "    - Coordinates of an accommodation as a list [latitude, longitude] (coords): list of floats\n",
    "\n",
    "    The data is scrapped from: https://www.immobiliare.it/\n",
    "\n",
    "    Inputs:\n",
    "\n",
    "    minPrice    (float): minimum price (rent),\n",
    "                default: 500\n",
    "\n",
    "    maxPrice    (float): maxmum price (rent),\n",
    "                default: 5000\n",
    "\n",
    "    maxPages    (float): number of result pages to be processed (50 items per page),\n",
    "                default: 10\n",
    "\n",
    "    dfPath      (str):  path to save dataframes as pickle files,\n",
    "                default: \"data/\"\n",
    "\n",
    "    savePickle  (bool): True, if pickle files should be saved to dfPath,\n",
    "          default: True\n",
    "\n",
    "    Outputs:\n",
    "\n",
    "    pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    urlList = [f\"https://www.immobiliare.it/affitto-case/milano/?criterio=rilevanza&prezzoMinimo={minPrice}&prezzoMassimo={maxPrice}\"]\n",
    "    urlList+=[f\"https://www.immobiliare.it/affitto-case/milano/?criterio=rilevanza&prezzoMinimo={minPrice}&prezzoMassimo={maxPrice}&pag={i+1}\" for i in range(maxPages)]\n",
    "\n",
    "    objects = {\"id\":[],\n",
    "               \"type\":[],\n",
    "               \"address\":[],\n",
    "               \"price\":[]}\n",
    "\n",
    "    for url in urlList:\n",
    "        session = requests.session()\n",
    "        response = session.get(url+\"&boxAuto[]=1&boxAuto[]=4\")\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        for element in soup.find_all('p', class_='titolo text-primary'):\n",
    "            try:\n",
    "                name = element.text.strip().split()\n",
    "                objects[\"id\"].append(element.find('a').get(\"id\"))\n",
    "                objects[\"type\"].append(name[0])\n",
    "                objects[\"address\"].append(\" \".join(name[1:]))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        for element in soup.find_all('li', class_='lif__item lif__pricing'):\n",
    "            try:\n",
    "                if element.find('div')==None:\n",
    "\n",
    "                    price = element.text.strip().split()[1]\n",
    "                    price= price.replace(\".\",\"\")\n",
    "                    objects[\"price\"].append(int(price))\n",
    "                else:\n",
    "\n",
    "                    price = element.find('div').text.strip().split()[1]\n",
    "                    price= price.replace(\".\",\"\")\n",
    "\n",
    "                    objects[\"price\"].append(int(price))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            #Sanity check\n",
    "    assert len(objects[\"id\"]) == len(objects[\"type\"]) == len(objects[\"address\"]) == len(objects[\"price\"])\n",
    "    print(f\"All successful. {len(objects['id'])} objects has been added\")\n",
    "\n",
    "    dfObjects = pd.DataFrame(objects)\n",
    "    dfObjects[\"coords\"] = dfObjects[\"address\"].map(getLoc)\n",
    "    dfObjects.dropna(inplace = True)\n",
    "    if savePickle:\n",
    "        dfObjects.to_pickle(dfPath+'dfObjects.pkl')\n",
    "    return dfObjects\n",
    "\n",
    "\n",
    "#\n",
    "# # ### Defining Zone for each object\n",
    "# import json\n",
    "# from shapely.geometry import shape, Point\n",
    "# with open('data/zonedecentramento.geojson') as f:\n",
    "#     js = json.load(f)\n",
    "#\n",
    "#\n",
    "# dfObjects[\"Zone\"] = dfObjects[\"coords\"].map(lambda x: getZone(x, js))\n",
    "#\n",
    "#\n",
    "# dfObjects= pd.merge(dfObjects, dfGreen, left_on='Zone', right_on=\"ZONADEC\", right_index=False, how='left', sort=False)\n",
    "#\n",
    "#\n",
    "#\n",
    "# dfObjects.drop(columns=[\"TotalArea\",\"GreenArea\", \"ZONADEC\"], inplace = True)\n",
    "#\n",
    "# dfObjects.columns = list(dfObjects.columns[:-1])+[\"GreenConc\"]\n",
    "#\n",
    "# dfObjects[\"lt\"] = dfObjects[\"coords\"].map(lambda x: x[0])\n",
    "# dfObjects[\"lg\"] = dfObjects[\"coords\"].map(lambda x: x[1])\n",
    "#\n",
    "#\n",
    "# dfObjects.to_csv(\"dfObjectsUnscored.csv\", index = False)\n",
    "#\n",
    "#\n",
    "# airWeight, safetyWeight, jobWeight, greenWeight, priceWeight  = 5, 5, 5, 5, 5\n",
    "#\n",
    "# dfObjects[[\"price\"]].hist()\n",
    "#\n",
    "#\n",
    "# # Let's scale it and transform using log function.\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# dfObjects[\"priceLogScaled\"] = scaler.fit_transform(np.log(dfObjects[[\"price\"]]))\n",
    "# numColumns = [\"priceLogScaled\", \"contamination\", \"distanceToDangerZone\",\n",
    "#                      \"distanceToMedianJobLocation\",\"GreenConc\"]\n",
    "# dfObjects[\"totalScore\"]=dfObjects.apply(lambda x: totalScore([x[i] for i in numColumns]), axis=1)\n",
    "# dfObjects\n",
    "#\n",
    "#\n",
    "# # In[ ]:\n",
    "#\n",
    "#\n",
    "# dfObjects[\"priceLogScaled\"].hist()\n",
    "#\n",
    "#\n",
    "# # ### Saving DF\n",
    "# dfObjects.to_csv(\"dfObjects.csv\", index = False)\n",
    "#\n",
    "#\n",
    "# # ### Creating a model for predicting price\n",
    "#\n",
    "# # #### Leaving only numerical columns\n",
    "#\n",
    "# # In[ ]:\n",
    "#\n",
    "#\n",
    "# numColumns = [\"price\", \"contamination\", \"distanceToDangerZone\",\n",
    "#                      \"distanceToMedianJobLocation\",\"GreenConc\"]\n",
    "# dfFinal = dfObjects[[\"price\", \"contamination\", \"distanceToDangerZone\",\n",
    "#                      \"distanceToMedianJobLocation\",\"GreenConc\"]]\n",
    "# dfFinal\n",
    "#\n",
    "#\n",
    "# # #### Scaling\n",
    "#\n",
    "# # In[ ]:\n",
    "#\n",
    "#\n",
    "# from sklearn import preprocessing\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# scaled = scaler.fit_transform(dfFinal)\n",
    "# dfFinal = pd.DataFrame(scaled)\n",
    "# dfFinal.columns = numColumns\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# priceWeight = 5\n",
    "# dfFinal[\"totalScore\"]=dfFinal.apply(lambda x: totalScore([x[i] for i in dfFinal.columns]), axis=1)\n",
    "# dfFinal\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# dfObjectsScored = pd.concat([dfObjects[[\"id\", \"type\", \"address\", \"price\",\"coords\",\"lt\",\"lg\"]], dfFinal[[\"totalScore\"]]], axis = 1)\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# dfObjectsScored.to_csv(\"dfObjectsScored.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "\u001b[K     |████████████████████████████████| 904 kB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /home/inotin/.local/lib/python3.8/site-packages (from selenium) (1.24.3)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mgeckodriver\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls /home/inotin/Documents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting careerjet-api-client\n",
      "  Downloading careerjet_api_client-3.0.1.tar.gz (3.5 kB)\n",
      "Requirement already satisfied: requests in /home/inotin/.local/lib/python3.8/site-packages (from careerjet-api-client) (2.21.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->careerjet-api-client) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3/dist-packages (from requests->careerjet-api-client) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/inotin/.local/lib/python3.8/site-packages (from requests->careerjet-api-client) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/inotin/.local/lib/python3.8/site-packages (from requests->careerjet-api-client) (2021.5.30)\n",
      "Building wheels for collected packages: careerjet-api-client\n",
      "  Building wheel for careerjet-api-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for careerjet-api-client: filename=careerjet_api_client-3.0.1-py3-none-any.whl size=4254 sha256=1876476d4bc48c6e903ba7f2667c90452032e2de28f9257680c78dd6829330da\n",
      "  Stored in directory: /home/inotin/.cache/pip/wheels/50/48/cb/a4ce98e9b5be16fbcfe49465cf438cd87aae054cd6ad17db32\n",
      "Successfully built careerjet-api-client\n",
      "Installing collected packages: careerjet-api-client\n",
      "Successfully installed careerjet-api-client-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install careerjet-api-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Firefox()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rc/clk?jk=116332180c9ab20f&fccid=d47acb5b5596d9e4&vjs=3\n",
      "Agent-Guest Services\n",
      "Marriott International, Inc\n",
      "==========\n",
      "/rc/clk?jk=6d9922699fbf799f&fccid=ac6d93e2692054b1&vjs=3\n",
      "JUNIOR INTERIOR DESIGNER\n",
      "Global Planning Architecture\n",
      "==========\n",
      "/rc/clk?jk=244d1c3cf1225823&fccid=a8c536c3d65bf125&vjs=3\n",
      "Architetto Designer / Luxury Brand\n",
      "Neon Ferrari Trada\n",
      "==========\n",
      "/rc/clk?jk=0074a17579ca296e&fccid=559dbeaee2b65abb&vjs=3\n",
      "Graphic designer\n",
      "Vectorealism\n",
      "==========\n",
      "/company/Intech-Srl---INTERFACEGLOBE/jobs/Web-Graphic-Designer-Freelance-369095fdd0ed1cc7?fccid=be7258780ffdce01&vjs=3\n",
      "Web and Graphic Designer Freelance\n",
      "Intech Srl - INTERFACEGLOBE\n",
      "==========\n",
      "/rc/clk?jk=ae7a875ef1dbe562&fccid=8e0ce4d27f76a735&vjs=3\n",
      "Graphic designer [Freelance]\n",
      "Figmenta Srl.\n",
      "==========\n",
      "/company/IVH-Group-Spa/jobs/Stage-Graphic-Designer-Linguaggio-HTML-5d519d81ea835ef3?fccid=6c56210295d6992a&vjs=3\n",
      "Stage Graphic designer e Linguaggio HTML\n",
      "IVH Group Spa\n",
      "==========\n",
      "/rc/clk?jk=66b87d14319453f3&fccid=b71ee43710135ed5&vjs=3\n",
      "PRODUCT DESIGNER\n",
      "PREMI S.P.A.\n",
      "==========\n",
      "/rc/clk?jk=5247edfc7369f5aa&fccid=0227baf05c429666&vjs=3\n",
      "Junior Graphic Designer\n",
      "Iliad Italia S.p.A.\n",
      "==========\n",
      "/rc/clk?jk=7d0c730a35c979e0&fccid=63aecc238913e49a&vjs=3\n",
      "UX Designer\n",
      "Playground\n",
      "==========\n",
      "/rc/clk?jk=a225538f57a9f4dd&fccid=c7fb5f7b576a671c&vjs=3\n",
      "UI DESIGNER\n",
      "BIP - Business Integration Partners\n",
      "==========\n",
      "/rc/clk?jk=283362afe2e0e86c&fccid=49bc124c9d739874&vjs=3\n",
      "Content Designer\n",
      "Caffeina Srl\n",
      "==========\n",
      "/company/Francioso-Comunicazione/jobs/Grafico-Creativo-8673eb871d51d00e?fccid=eece725f77f279f0&vjs=3\n",
      "Grafico creativo\n",
      "Francioso Comunicazione\n",
      "==========\n",
      "/rc/clk?jk=f7809a7974330a9f&fccid=c1d1194b84039bfa&vjs=3\n",
      "Graphic designer\n",
      "Jellyfish\n",
      "==========\n",
      "/rc/clk?jk=3b099edad70681da&fccid=dd616958bd9ddc12&vjs=3\n",
      "Product Designer (MI)\n",
      "azienda/studio: Dainelli Studio\n",
      "==========\n",
      "/rc/clk?jk=5b809b70ab825f43&fccid=92d373ef3017b6b5&vjs=3\n",
      "INTERIOR DESIGNER\n",
      "During\n",
      "==========\n",
      "/rc/clk?jk=f687466422589aba&fccid=b6297974c1bd788d&vjs=3\n",
      "Graphic Designer\n",
      "Business Competence srl\n",
      "==========\n",
      "/rc/clk?jk=5783db033766f2d1&fccid=3f4cc0c1ee71fc47&vjs=3\n",
      "Studio internazionale di architettura cerca Junior Interior...\n",
      "azienda/studio: Studio matteo Nunziati\n",
      "==========\n",
      "/company/EMME&E-s.r.l./jobs/Grafico-Impaginatore-b98a5ed877264509?fccid=abd4b444f31aed98&vjs=3\n",
      "Grafico impaginatore\n",
      "EMME&E s.r.l.\n",
      "==========\n",
      "/rc/clk?jk=a6e9d437d5126ffe&fccid=f97eb516aad197a5&vjs=3\n",
      "Digital Visual Content Designer\n",
      "The Digital Project\n",
      "==========\n",
      "/rc/clk?jk=5e5a1c32e6ec328c&fccid=16c4cf915e1d76d9&vjs=3\n",
      "Web Graphic Designer\n",
      "Endivia S.r.l.\n",
      "==========\n",
      "/company/BdueB-Milano/jobs/Graphic-Web-Designer-5b8e4186388250aa?fccid=3a67503abc6d4f9b&vjs=3\n",
      "Graphic & Web Designer\n",
      "BdueB Milano\n",
      "==========\n",
      "/company/Alimonti-Srl/jobs/Architetto-e2424b65d47c46fd?fccid=fae4b4a4fccc94b3&vjs=3\n",
      "Architetto / Designer\n",
      "Alimonti Srl\n",
      "==========\n",
      "/rc/clk?jk=321e7720e5e98be5&fccid=d88f133a1a6e2fdb&vjs=3\n",
      "Digital Visual and Content Designer\n",
      "SDG Group\n",
      "==========\n",
      "/company/Finsa-S.p.A/jobs/Ux-Ui-Designer-Junior-e7f9f3dca1a8aecd?fccid=b22db4c838fd9596&vjs=3\n",
      "UX/UI Designer Junior\n",
      "Finsa S.p.A\n",
      "==========\n",
      "/company/M.I.A.-SRL/jobs/Assistente-Interior-Designer-ad39ff9a5a73a40d?fccid=b84b795302cfbc81&vjs=3\n",
      "Assistente Interior Designer - Stage\n",
      "M.I.A. SRL\n",
      "==========\n",
      "/rc/clk?jk=87472238e42781cd&fccid=a49d99f2875604a1&vjs=3\n",
      "In-store Graphic Designer\n",
      "Luxottica\n",
      "==========\n",
      "/rc/clk?jk=e19e5f4838d5bfc1&fccid=a49d99f2875604a1&vjs=3\n",
      "In-store Graphic Designer\n",
      "Luxottica Group\n",
      "==========\n",
      "/rc/clk?jk=d1eea94395b8fc7e&fccid=a49d99f2875604a1&vjs=3\n",
      "Digital Graphic Designer\n",
      "Luxottica Group\n",
      "==========\n",
      "/rc/clk?jk=e1faa1420534f3d7&fccid=a49d99f2875604a1&vjs=3\n",
      "Digital Graphic Designer\n",
      "Luxottica\n",
      "==========\n",
      "/rc/clk?jk=f29edd3cf725d468&fccid=866cab71fab682c0&vjs=3\n",
      "Graphic Designer\n",
      "Balich Worldwide Shows\n",
      "==========\n",
      "/rc/clk?jk=1c6e604cb8d73fa3&fccid=d47acb5b5596d9e4&vjs=3\n",
      "Server\n",
      "Marriott International, Inc\n",
      "==========\n",
      "/rc/clk?jk=155cda452c6a2091&fccid=a49d99f2875604a1&vjs=3\n",
      "UI Designer\n",
      "Luxottica Group\n",
      "==========\n",
      "/rc/clk?jk=920dba2e8e2750a7&fccid=dd616958bd9ddc12&vjs=3\n",
      "Architetto / Designer / Interior orientato al Lighting Desig...\n",
      "azienda/studio: Arli Luce by Daucus Srl\n",
      "==========\n",
      "/rc/clk?jk=7c692182e8dffeb2&fccid=ebba295d1c3ec904&vjs=3\n",
      "UX/UI DESIGNER\n",
      "Milestone srl\n",
      "==========\n",
      "/rc/clk?jk=7d2173a0d0e98a82&fccid=a8c536c3d65bf125&vjs=3\n",
      "Designer Creativo\n",
      "Neon Ferrari Trada\n",
      "==========\n",
      "/rc/clk?jk=fb60728c68d21b81&fccid=cbb88f950f795219&vjs=3\n",
      "Motion Graphic Designer Freelance\n",
      "White Marketing and Communication Srl\n",
      "==========\n",
      "/rc/clk?jk=07d4bad58e76712c&fccid=0488207e1482f550&vjs=3\n",
      "UX/UI Designer\n",
      "Luna Labs Srl\n",
      "==========\n",
      "/rc/clk?jk=01e1693285d861a4&fccid=2dd390c3a48a7ed0&vjs=3\n",
      "UI Designer - Consultant\n",
      "KPMG\n",
      "==========\n",
      "/rc/clk?jk=26f9dd77d590df11&fccid=a8a8f5986775299f&vjs=3\n",
      "UX-UI Designer\n",
      "Avangarde Consulting\n",
      "==========\n",
      "/rc/clk?jk=d0a0815db8264af9&fccid=ae56c8d50931c2ef&vjs=3\n",
      "Campaign & Content Designer\n",
      "Everli\n",
      "==========\n",
      "/rc/clk?jk=8b37556e67115a25&fccid=28f79c18789111e8&vjs=3\n",
      "Senior Layout Designer\n",
      "Hitachi Zosen Inova\n",
      "==========\n",
      "/company/Agenziapi%C3%B9-Spa---Sesto-San-Giovanni/jobs/Grafico-b9df948f1dde4372?fccid=3fac35745554088b&vjs=3\n",
      "grafico / graphic design / digital- web designer\n",
      "Agenziapiù Spa - Sesto San Giovanni\n",
      "==========\n",
      "/company/Notarify/jobs/Graphic-Web-Designer-76eb72a8443e4b89?fccid=dfd5d85a47a1934a&vjs=3\n",
      "Graphic & Web Designer - Stage\n",
      "Notarify\n",
      "==========\n",
      "/company/CSS-CENTRO-STAMPA-E-SERVIZI/jobs/Operatore-Grafico-0f8a05baffded11e?fccid=20bb94e0f2bf060c&vjs=3\n",
      "Operatore grafico\n",
      "CSS CENTRO STAMPA E SERVIZI\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "companyInfo = {\"companyName\":[],\n",
    "               \"jobName\":[],\n",
    "               \"link\":[],\n",
    "               \"lt\" : [],\n",
    "               \"lg\" : [],\n",
    "               \"address\" : []}\n",
    "for url in urlList:\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "   \n",
    "    for element in soup.find_all('a', id=re.compile('^job_')):\n",
    "    #     print(element)\n",
    "\n",
    "        print(element['href'])\n",
    "        jobName = element.find('span', class_=lambda x: x != 'label').text\n",
    "        print(jobName)\n",
    "        companyInfo[\"link\"].append(\"https://it.indeed.com\"+str(element['href']))\n",
    "        companyInfo[\"jobName\"].append(jobName)\n",
    "        name = element.find('span', class_='companyName').text\n",
    "        print(name)\n",
    "        companyInfo[\"companyName\"].append(name)\n",
    "        print('='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://it.indeed.com/offerte-lavoro?q=designer&l=Milano%2C+Lombardia', 'https://it.indeed.com/jobs?q=designer&l=Milano%2C+Lombardia&start=10', 'https://it.indeed.com/jobs?q=designer&l=Milano%2C+Lombardia&start=20']\n"
     ]
    }
   ],
   "source": [
    "jobName = 'designer'\n",
    "jobName = \"+\".join(jobName.split())\n",
    "locationName= 'Milano Lombardia'\n",
    "city = locationName.split()[0]\n",
    "locationName = \"%2C+\".join(locationName.split())\n",
    "resource = \"https://it.indeed.com/\"\n",
    "maxPages=2\n",
    "#To be extended if other resources are used\n",
    "if resource == \"https://it.indeed.com/\":\n",
    "    if maxPages>1:\n",
    "        urlList = [f\"https://it.indeed.com/offerte-lavoro?q={jobName}&l={locationName}\"]\n",
    "        urlList+=[f\"https://it.indeed.com/jobs?q={jobName}&l={locationName}&start={i}0\" for i in range(1,maxPages+1)]\n",
    "    else:\n",
    "        urlList = [f\"https://it.indeed.com/offerte-lavoro?q={jobName}&l={locationName}\"]\n",
    "\n",
    "\n",
    "print(urlList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rc/clk?jk=0074a17579ca296e&fccid=559dbeaee2b65abb&vjs=3\n",
      "Graphic designer\n",
      "Vectorealism\n",
      "==========\n",
      "/rc/clk?jk=116332180c9ab20f&fccid=d47acb5b5596d9e4&vjs=3\n",
      "Agent-Guest Services\n",
      "Marriott International, Inc\n",
      "==========\n",
      "/rc/clk?jk=6d9922699fbf799f&fccid=ac6d93e2692054b1&vjs=3\n",
      "JUNIOR INTERIOR DESIGNER\n",
      "Global Planning Architecture\n",
      "==========\n",
      "/rc/clk?jk=3b099edad70681da&fccid=dd616958bd9ddc12&vjs=3\n",
      "Product Designer (MI)\n",
      "azienda/studio: Dainelli Studio\n",
      "==========\n",
      "/rc/clk?jk=244d1c3cf1225823&fccid=a8c536c3d65bf125&vjs=3\n",
      "Architetto Designer / Luxury Brand\n",
      "Neon Ferrari Trada\n",
      "==========\n",
      "/rc/clk?jk=f29edd3cf725d468&fccid=866cab71fab682c0&vjs=3\n",
      "Graphic Designer\n",
      "Balich Worldwide Shows\n",
      "==========\n",
      "/rc/clk?jk=4d72086ffafd4f35&fccid=6dada33a272e0615&vjs=3\n",
      "PRODUCT DESIGNER\n",
      "Premi Spa\n",
      "==========\n",
      "/rc/clk?jk=d1eea94395b8fc7e&fccid=a49d99f2875604a1&vjs=3\n",
      "Digital Graphic Designer\n",
      "Luxottica Group\n",
      "==========\n",
      "/rc/clk?jk=5247edfc7369f5aa&fccid=0227baf05c429666&vjs=3\n",
      "Junior Graphic Designer\n",
      "Iliad Italia S.p.A.\n",
      "==========\n",
      "/rc/clk?jk=e2d8108a741327c7&fccid=ca2b244e2a15ca5c&vjs=3\n",
      "Motion Grapher Designer\n",
      "Experis\n",
      "==========\n",
      "/rc/clk?jk=e19e5f4838d5bfc1&fccid=a49d99f2875604a1&vjs=3\n",
      "In-store Graphic Designer\n",
      "Luxottica Group\n",
      "==========\n",
      "/rc/clk?jk=ae7a875ef1dbe562&fccid=8e0ce4d27f76a735&vjs=3\n",
      "Graphic designer [Freelance]\n",
      "Figmenta Srl.\n",
      "==========\n",
      "/company/BdueB-Milano/jobs/Graphic-Web-Designer-5b8e4186388250aa?fccid=3a67503abc6d4f9b&vjs=3\n",
      "Graphic & Web Designer\n",
      "BdueB Milano\n",
      "==========\n",
      "/rc/clk?jk=f7809a7974330a9f&fccid=c1d1194b84039bfa&vjs=3\n",
      "Graphic designer\n",
      "Jellyfish\n",
      "==========\n",
      "/rc/clk?jk=155cda452c6a2091&fccid=a49d99f2875604a1&vjs=3\n",
      "UI Designer\n",
      "Luxottica Group\n",
      "==========\n",
      "/rc/clk?jk=5783db033766f2d1&fccid=3f4cc0c1ee71fc47&vjs=3\n",
      "Studio internazionale di architettura cerca Junior Interior...\n",
      "azienda/studio: Studio matteo Nunziati\n",
      "==========\n",
      "/company/EMME&E-s.r.l./jobs/Grafico-Impaginatore-b98a5ed877264509?fccid=abd4b444f31aed98&vjs=3\n",
      "Grafico impaginatore\n",
      "EMME&E s.r.l.\n",
      "==========\n",
      "/rc/clk?jk=f687466422589aba&fccid=b6297974c1bd788d&vjs=3\n",
      "Graphic Designer\n",
      "Business Competence srl\n",
      "==========\n",
      "/company/BdueB-Milano/jobs/Graphic-Web-Designer-5b8e4186388250aa?fccid=3a67503abc6d4f9b&vjs=3\n",
      "Graphic & Web Designer\n",
      "BdueB Milano\n",
      "==========\n",
      "/rc/clk?jk=a6e9d437d5126ffe&fccid=f97eb516aad197a5&vjs=3\n",
      "Digital Visual Content Designer\n",
      "The Digital Project\n",
      "==========\n",
      "/rc/clk?jk=1c6e604cb8d73fa3&fccid=d47acb5b5596d9e4&vjs=3\n",
      "Server\n",
      "Marriott International, Inc\n",
      "==========\n",
      "/company/Alimonti-Srl/jobs/Architetto-e2424b65d47c46fd?fccid=fae4b4a4fccc94b3&vjs=3\n",
      "Architetto / Designer\n",
      "Alimonti Srl\n",
      "==========\n",
      "/company/M.I.A.-SRL/jobs/Assistente-Interior-Designer-ad39ff9a5a73a40d?fccid=b84b795302cfbc81&vjs=3\n",
      "Assistente Interior Designer - Stage\n",
      "M.I.A. SRL\n",
      "==========\n",
      "/rc/clk?jk=5e5a1c32e6ec328c&fccid=16c4cf915e1d76d9&vjs=3\n",
      "Web Graphic Designer\n",
      "Endivia S.r.l.\n",
      "==========\n",
      "/company/Finsa-S.p.A/jobs/Ux-Ui-Designer-Junior-e7f9f3dca1a8aecd?fccid=b22db4c838fd9596&vjs=3\n",
      "UX/UI Designer Junior\n",
      "Finsa S.p.A\n",
      "==========\n",
      "/rc/clk?jk=920dba2e8e2750a7&fccid=dd616958bd9ddc12&vjs=3\n",
      "Architetto / Designer / Interior orientato al Lighting Desig...\n",
      "azienda/studio: Arli Luce by Daucus Srl\n",
      "==========\n",
      "/rc/clk?jk=155cda452c6a2091&fccid=a49d99f2875604a1&vjs=3\n",
      "UI Designer\n",
      "Luxottica Group\n",
      "==========\n",
      "/rc/clk?jk=f29edd3cf725d468&fccid=866cab71fab682c0&vjs=3\n",
      "Graphic Designer\n",
      "Balich Worldwide Shows\n",
      "==========\n",
      "/rc/clk?jk=d1eea94395b8fc7e&fccid=a49d99f2875604a1&vjs=3\n",
      "Digital Graphic Designer\n",
      "Luxottica Group\n",
      "==========\n",
      "/rc/clk?jk=e1faa1420534f3d7&fccid=a49d99f2875604a1&vjs=3\n",
      "Digital Graphic Designer\n",
      "Luxottica\n",
      "==========\n",
      "/company/Matteo-Thun-&-Partners-srl/jobs/Stage-Junior-Product-Designer-0a1248ac2eef5988?fccid=efab0593745a394f&vjs=3\n",
      "Stage Junior Product Designer\n",
      "Matteo Thun & Partners srl\n",
      "==========\n",
      "/rc/clk?jk=29d60b4a9e2ade30&fccid=aad2a909d9e6efb5&vjs=3\n",
      "learning designer\n",
      "UNIVERSITA' DI MILANO\n",
      "==========\n",
      "/rc/clk?jk=7c692182e8dffeb2&fccid=ebba295d1c3ec904&vjs=3\n",
      "UX/UI DESIGNER\n",
      "Milestone srl\n",
      "==========\n",
      "/rc/clk?jk=e70cc9d9346db5eb&fccid=da3c7fed78dd1607&vjs=3\n",
      "Senior Interaction Designer\n",
      "Samsung Electronics\n",
      "==========\n",
      "/rc/clk?jk=517e9522bf02a0fc&fccid=ec28adc427c0458f&vjs=3\n",
      "CAD Designer\n",
      "F.lli GALLI\n",
      "==========\n",
      "/company/Matteo-Thun-&-Partners-srl/jobs/Senior-Interior-Designer-4bacf18c9d5b660a?fccid=efab0593745a394f&vjs=3\n",
      "Senior Interior Designer\n",
      "Matteo Thun & Partners srl\n",
      "==========\n",
      "/rc/clk?jk=283362afe2e0e86c&fccid=49bc124c9d739874&vjs=3\n",
      "Content Designer\n",
      "Caffeina Srl\n",
      "==========\n",
      "/rc/clk?jk=9fe99e67ed13c99a&fccid=ae56c8d50931c2ef&vjs=3\n",
      "Illustration and Motion Designer\n",
      "Everli\n",
      "==========\n",
      "/rc/clk?jk=cd3b9e4584b84a90&fccid=36bb9fab1eeb83a2&vjs=3\n",
      "Associate Product Experience Designer with ID Background\n",
      "Continuum\n",
      "==========\n",
      "/rc/clk?jk=1c6e604cb8d73fa3&fccid=d47acb5b5596d9e4&vjs=3\n",
      "Server\n",
      "Marriott International, Inc\n",
      "==========\n",
      "/rc/clk?jk=bd54db40dfa861e7&fccid=fce3867caeb7481f&vjs=3\n",
      "Digital Designer\n",
      "Subito\n",
      "==========\n",
      "/rc/clk?jk=5783db033766f2d1&fccid=3f4cc0c1ee71fc47&vjs=3\n",
      "Studio internazionale di architettura cerca Junior Interior...\n",
      "azienda/studio: Studio matteo Nunziati\n",
      "==========\n",
      "/rc/clk?jk=a6e9d437d5126ffe&fccid=f97eb516aad197a5&vjs=3\n",
      "Digital Visual Content Designer\n",
      "The Digital Project\n",
      "==========\n",
      "/rc/clk?jk=f59af77128c5b1ea&fccid=866cab71fab682c0&vjs=3\n",
      "Art Director (full-time)\n",
      "Balich Worldwide Shows\n",
      "==========\n",
      "/rc/clk?jk=a49245d5dfe5649d&fccid=ba3dd2a1343dd7ea&vjs=3\n",
      "Graphic Designer per materiale tecnico\n",
      "Minotti\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "companyInfo = {\"companyName\":[],\n",
    "               \"jobName\":[],\n",
    "               \"link\":[],\n",
    "               \"lt\" : [],\n",
    "               \"lg\" : [],\n",
    "               \"address\" : []}\n",
    "# input(urlList)\n",
    "for url in urlList:\n",
    "    session = requests.session()\n",
    "    response = session.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "   \n",
    "    for element in soup.find_all('a', id=re.compile('^job_')):\n",
    "    #     print(element)\n",
    "\n",
    "        print(element['href'])\n",
    "        jobName = element.find('span', class_=lambda x: x != 'label').text\n",
    "        print(jobName)\n",
    "        companyInfo[\"link\"].append(\"https://it.indeed.com\"+str(element['href']))\n",
    "        companyInfo[\"jobName\"].append(jobName)\n",
    "        name = element.find('span', class_='companyName').text\n",
    "        print(name)\n",
    "        companyInfo[\"companyName\"].append(name)\n",
    "        print('='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "45\n",
      "45\n",
      "Vectorealism\n",
      "OK\n",
      "\n",
      "Vectorealism was succesfully added with address:\n",
      "Via Carlo Boncompagni, 57, 20139 Milano MI, Italy\n",
      "\n",
      "Marriott International, Inc\n",
      "OK\n",
      "\n",
      "Marriott International, Inc was skipped. 8051 NW 36th St, Doral, FL 33166, USA is not in Milano\n",
      "\n",
      "Global Planning Architecture\n",
      "OK\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6bcdadcc3abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mnumberOfAttempt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreqStatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#print(f'Attempt {numberOfAttempt} for {company}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "print(len(companyInfo[\"companyName\"]))\n",
    "print(len(companyInfo[\"jobName\"]))\n",
    "print(len(companyInfo[\"link\"]))\n",
    "# input()\n",
    "assert len(companyInfo[\"companyName\"]) == len(companyInfo[\"jobName\"]) == len(companyInfo[\"link\"])\n",
    "\n",
    "# In order to get companies' locations I need their address which I can get using Google Maps API.\n",
    "# I had to create an account for that purpose.\n",
    "# Credentials are stored in googleCreds.py for security reasons.\n",
    "geolocator = GoogleV3(api_key = googleCreds.GOOGLE_API_KEY)\n",
    "\n",
    "for company in companyInfo[\"companyName\"]:\n",
    "    print(company)\n",
    "    rawName = str(company+\" Milano\").replace(\" \",\"+\")\n",
    "\n",
    "    url = 'https://maps.googleapis.com/maps/api/geocode/json?'+'address={}&key={}'.format(rawName,googleCreds.GOOGLE_API_KEY)\n",
    "    p = {'address' : 'Milano'}\n",
    "    reqStatus = None\n",
    "    attemptsLimit = 10\n",
    "    numberOfAttempt = 0\n",
    "    # while reqStatus!='OK' or numberOfAttempt<=attemptsLimit:\n",
    "    r = requests.get(url, params = p).json()\n",
    "    reqStatus=r['status']\n",
    "    numberOfAttempt+=1\n",
    "    print(reqStatus)\n",
    "    input()\n",
    "    time.sleep(0.5)\n",
    "    #print(f'Attempt {numberOfAttempt} for {company}')\n",
    "    # try:\n",
    "\n",
    "    results = r['results']\n",
    "    try:\n",
    "        results = results[0]\n",
    "\n",
    "        location = geolocator.geocode(results[\"formatted_address\"])\n",
    "        if \"Milan\" in location.address:\n",
    "            print(company + \" was succesfully added with address:\\n\" + location.address + \"\\n\")\n",
    "\n",
    "            companyInfo[\"lt\"].append(location.latitude)\n",
    "            companyInfo[\"lg\"].append(location.longitude)\n",
    "            companyInfo[\"address\"].append(location.address)\n",
    "        else:\n",
    "            print(company + \" was skipped. \"+location.address+\" is not in Milano\\n\")\n",
    "            companyInfo[\"lt\"].append(np.nan)\n",
    "            companyInfo[\"lg\"].append(np.nan)\n",
    "            companyInfo[\"address\"].append(np.nan)\n",
    "    except:\n",
    "        print(company + \" was skipped. Probably was not found\\n\")\n",
    "        companyInfo[\"lt\"].append(np.nan)\n",
    "        companyInfo[\"lg\"].append(np.nan)\n",
    "        companyInfo[\"address\"].append(np.nan)\n",
    "\n",
    "#Sanity check if any info was lost/missed\n",
    "assert len(companyInfo[\"companyName\"]) == len(companyInfo[\"jobName\"]) == len(companyInfo[\"link\"])\n",
    "assert len(companyInfo[\"lt\"]) == len(companyInfo[\"lg\"]) == len(companyInfo[\"address\"]) == len(companyInfo[\"link\"])\n",
    "print(\"Assertion succesful. Creating Dataframe\")\n",
    "\n",
    "dfCompanies = pd.DataFrame(companyInfo)\n",
    "dfCompanies = dfCompanies[dfCompanies[\"address\"].astype(str).str.contains(city)]\n",
    "\n",
    "\n",
    "dfCompanies.dropna(inplace = True)\n",
    "dfCompanies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
